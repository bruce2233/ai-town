version: '3.8'

services:
  llm-gateway:
    build: ./llm-gateway
    ports:
      - "8081:8081"
    environment:
      - PORT=8081
      - OPENAI_API_KEY=${OPENAI_API_KEY:-sk-dummy}
      - LLM_PROVIDER_URL=${LLM_PROVIDER_URL}
      - LLM_PROVIDER_KEY=${LLM_PROVIDER_KEY}
      - NODE_ENV=development
    networks:
      - ai-town-net

  world:
    build: ./world
    depends_on:
      - llm-gateway
    volumes:
      - ./world:/app
      - /app/node_modules
    environment:
      - LLM_API_URL=http://llm-gateway:8081/v1
      - LLM_API_KEY=${LLM_API_KEY:-dummy}
      - MODEL_NAME=${MODEL_NAME:-Qwen/Qwen3-4B-Instruct}
      - NODE_ENV=development
    networks:
      - ai-town-net

  frontend:
    build: ./frontend
    ports:
      - "5173:5173"
    environment:
      # VITE_GATEWAY_URL is removed to allow dynamic detection of host (LAN support)
      - NODE_ENV=development
    networks:
      - ai-town-net

networks:
  ai-town-net:
    driver: bridge
